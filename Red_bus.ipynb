{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nV1Iyb068gaL"
      },
      "outputs": [],
      "source": [
        "# STEP 1: IMPORT LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: LOAD DATA\n",
        "train = pd.read_csv(\"train.csv\", parse_dates=['doj'])\n",
        "test = pd.read_csv(\"/content/test_8gqdJqH.csv\", parse_dates=['doj'])\n",
        "transactions = pd.read_csv(\"transactions.csv\", parse_dates=['doj', 'doi'])\n"
      ],
      "metadata": {
        "id": "OHjRKdB09D4l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: FILTER TRANSACTIONS FOR DBD=15\n",
        "trans_15 = transactions[transactions['dbd'] == 15].copy()"
      ],
      "metadata": {
        "id": "Pu3v0NCN9KxM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: MERGE TRAIN & TEST WITH TRANS_15\n",
        "train_merged = pd.merge(train, trans_15, on=['doj', 'srcid', 'destid'], how='left')\n",
        "test_merged = pd.merge(test, trans_15, on=['doj', 'srcid', 'destid'], how='left')"
      ],
      "metadata": {
        "id": "WX3k-4wi9NSj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: FEATURE ENGINEERING FUNCTION\n",
        "def create_features(df):\n",
        "    df['day_of_week'] = df['doj'].dt.weekday\n",
        "    df['month'] = df['doj'].dt.month\n",
        "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
        "    df['route'] = df['srcid'].astype(str) + '_' + df['destid'].astype(str)\n",
        "    df['search_to_book_ratio'] = df['cumsum_searchcount'] / (df['cumsum_seatcount'] + 1)\n",
        "    df['search_to_book_ratio'] = df['search_to_book_ratio'].clip(upper=100)  # cap extreme values\n",
        "    # Encode region and tier\n",
        "    for col in ['srcid_region', 'destid_region', 'srcid_tier', 'destid_tier']:\n",
        "        if col in df.columns:\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "    return df\n",
        "\n",
        "train_feat = create_features(train_merged.copy())\n",
        "test_feat = create_features(test_merged.copy())"
      ],
      "metadata": {
        "id": "i3PM8Qlk9Pj9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: DEFINE FEATURES & TARGET\n",
        "features = [\n",
        "    'day_of_week', 'month', 'is_weekend',\n",
        "    'srcid', 'destid', 'srcid_region', 'destid_region',\n",
        "    'srcid_tier', 'destid_tier',\n",
        "    'cumsum_seatcount', 'cumsum_searchcount', 'search_to_book_ratio'\n",
        "]\n",
        "target = 'final_seatcount'\n",
        "\n",
        "# Fill missing values\n",
        "for df in [train_feat, test_feat]:\n",
        "    df[features] = df[features].fillna(-1)\n",
        "\n",
        "X = train_feat[features]\n",
        "y = train_feat[target]\n",
        "X_test = test_feat[features]"
      ],
      "metadata": {
        "id": "4DUHvjbp9VXl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: STACKING SETUP\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Out-of-fold and test predictions\n",
        "oof_lgb = np.zeros(len(X))\n",
        "oof_xgb = np.zeros(len(X))\n",
        "oof_ridge = np.zeros(len(X))\n",
        "\n",
        "preds_test_lgb = np.zeros(len(X_test))\n",
        "preds_test_xgb = np.zeros(len(X_test))\n",
        "preds_test_ridge = np.zeros(len(X_test))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # LightGBM using low-level API\n",
        "    lgb_train = lgb.Dataset(X_train, y_train)\n",
        "    lgb_val = lgb.Dataset(X_val, y_val)\n",
        "    lgb_model = lgb.train({\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'learning_rate': 0.05,\n",
        "        'verbosity': -1\n",
        "    },\n",
        "    train_set=lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_train, lgb_val])\n",
        "\n",
        "    oof_lgb[val_idx] = lgb_model.predict(X_val)\n",
        "    preds_test_lgb += lgb_model.predict(X_test) / n_splits\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_model = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
        "    xgb_model.fit(X_train, y_train,\n",
        "                  eval_set=[(X_val, y_val)],\n",
        "                  verbose=False)\n",
        "    oof_xgb[val_idx] = xgb_model.predict(X_val)\n",
        "    preds_test_xgb += xgb_model.predict(X_test) / n_splits\n",
        "\n",
        "    # Ridge\n",
        "    ridge_model = Ridge(alpha=1.0)\n",
        "    ridge_model.fit(X_train, y_train)\n",
        "    oof_ridge[val_idx] = ridge_model.predict(X_val)\n",
        "    preds_test_ridge += ridge_model.predict(X_test) / n_splits"
      ],
      "metadata": {
        "id": "_1eJF4Wf9ZnN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: TRAIN META-MODEL\n",
        "X_meta = np.vstack([oof_lgb, oof_xgb, oof_ridge]).T\n",
        "X_meta_test = np.vstack([preds_test_lgb, preds_test_xgb, preds_test_ridge]).T\n",
        "\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "meta_model.fit(X_meta, y)\n",
        "preds_final = meta_model.predict(X_meta_test)\n",
        "\n",
        "# Overall ensemble RMSE\n",
        "final_rmse = np.sqrt(mean_squared_error(y, meta_model.predict(X_meta)))\n",
        "print(f\"\\nFinal Ensemble RMSE: {final_rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymhcvXue9dmH",
        "outputId": "e5f4efc0-4cb3-47b2-c83a-f68d297cd425"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Ensemble RMSE: 537.9984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: CREATE SUBMISSION\n",
        "submission = pd.DataFrame({\n",
        "    'route_key': test['route_key'],\n",
        "    'final_seatcount': preds_final.round().astype(int)\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission file saved as 'submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qq7Dv20_61K",
        "outputId": "eb42dd2d-ecc8-41dc-9c9a-6eab4201c391"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved as 'submission.csv'\n"
          ]
        }
      ]
    }
  ]
}